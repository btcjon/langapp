




PromptLayer ChatOpenAI | ü¶úÔ∏èüîó Langchain





Skip to main contentü¶úÔ∏èüîó LangChainJS/TS DocsGitHubCTRLKGet startedIntroductionInstallationQuickstartModulesModel I/‚ÄãOPromptsLanguage modelsLLMsChat modelsHow-toIntegrationsAnthropicAzureGoogle Cloud Platform Vertex AI PaLMJinaChatOpenAIPromptLayer ChatOpenAIOutput parsersData connectionChainsMemoryAgentsCallbacksModulesUse casesGuidesEcosystemAdditional resourcesAPI referenceModulesModel I/‚ÄãOLanguage modelsChat modelsIntegrationsPromptLayer ChatOpenAIOn this pagePromptLayer ChatOpenAIThis example showcases how to connect to PromptLayer to start recording your ChatOpenAI requests.Install PromptLayer‚ÄãThe promptlayer package is required to use PromptLayer with OpenAI. Install promptlayer using pip.pip install promptlayerImports‚Äãimport osfrom langchain.chat_models import PromptLayerChatOpenAIfrom langchain.schema import HumanMessageSet the Environment API Key‚ÄãYou can create a PromptLayer API Key at www.promptlayer.com by clicking the settings cog in the navbar.Set it as an environment variable called PROMPTLAYER_API_KEY.os.environ["PROMPTLAYER_API_KEY"] = "**********"Use the PromptLayerOpenAI LLM like normal‚ÄãYou can optionally pass in pl_tags to track your requests with PromptLayer's tagging feature.chat = PromptLayerChatOpenAI(pl_tags=["langchain"])chat([HumanMessage(content="I am a cat and I want")])    AIMessage(content='to take a nap in a cozy spot. I search around for a suitable place and finally settle on a soft cushion on the window sill. I curl up into a ball and close my eyes, relishing the warmth of the sun on my fur. As I drift off to sleep, I can hear the birds chirping outside and feel the gentle breeze blowing through the window. This is the life of a contented cat.', additional_kwargs={})The above request should now appear on your PromptLayer dashboard.Using PromptLayer Track‚ÄãIf you would like to use any of the PromptLayer tracking features, you need to pass the argument return_pl_id when instantializing the PromptLayer LLM to get the request id.  chat = PromptLayerChatOpenAI(return_pl_id=True)chat_results = chat.generate([[HumanMessage(content="I am a cat and I want")]])for res in chat_results.generations:    pl_request_id = res[0].generation_info["pl_request_id"]    promptlayer.track.score(request_id=pl_request_id, score=100)Using this allows you to track the performance of your model in the PromptLayer dashboard. If you are using a prompt template, you can attach a template to a request as well.
Overall, this gives you the opportunity to track the performance of different templates and models in the PromptLayer dashboard.PreviousOpenAINextOutput parsersInstall PromptLayerImportsSet the Environment API KeyUse the PromptLayerOpenAI LLM like normalUsing PromptLayer TrackCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc.




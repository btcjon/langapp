




Recursive URL Loader | ü¶úÔ∏èüîó Langchain





Skip to main contentü¶úÔ∏èüîó LangChainJS/TS DocsGitHubCTRLKGet startedIntroductionInstallationQuickstartModulesModel I/‚ÄãOData connectionDocument loadersHow-toIntegrationsacreomAirbyte JSONAirtableAlibaba Cloud MaxComputeApify DatasetArxivAWS S3 DirectoryAWS S3 FileAZLyricsAzure Blob Storage ContainerAzure Blob Storage FileBibTeXBiliBiliBlackboardBlockchainBrave Searchchatgpt_loaderCollege ConfidentialConfluenceCoNLL-UCopy PasteCSVCube Semantic LayerDatadog LogsDiffbotDiscordDocugamiDuckDBEmailEmbaasEPubEverNoteexample_dataMicrosoft ExcelFacebook ChatFaunaFigmaGitGitBookGitHubGoogle BigQueryGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle DriveGrobidGutenbergHacker NewsHuggingFace datasetiFixitImagesImage captionsIMSDbIuguJoplinJupyter NotebookLarkSuite (FeiShu)MastodonMediaWikiDumpMergeDocLoadermhtmlMicrosoft OneDriveMicrosoft PowerPointMicrosoft WordModern TreasuryNotion DB 1/2Notion DB 2/2ObsidianOpen Document Format (ODT)Open City DataOrg-modePandas DataFramePsychicPySpark DataFrame LoaderReadTheDocs DocumentationRecursive URL LoaderRedditRoamRSTSitemapSlackSnowflakeSource CodeSpreedlyStripeSubtitleTelegramTencent COS DirectoryTencent COS File2MarkdownTOMLTrelloTSVTwitterUnstructured FileURLWeatherWebBaseLoaderWhatsApp ChatWikipediaXMLXorbits Pandas DataFrameLoading documents from a YouTube urlYouTube transcriptsDocument transformersText embedding modelsVector storesRetrieversChainsMemoryAgentsCallbacksModulesUse casesGuidesEcosystemAdditional resourcesAPI referenceModulesData connectionDocument loadersIntegrationsRecursive URL LoaderRecursive URL LoaderWe may want to process load all URLs under a root directory.For example, let's look at the LangChain JS documentation.This has many interesting child pages that we may want to read in bulk.Of course, the WebBaseLoader can load a list of pages. But, the challenge is traversing the tree of child pages and actually assembling that list!We do this using the RecursiveUrlLoader.This also gives us the flexibility to exclude some children (e.g., the api directory with > 800 child pages).from langchain.document_loaders.recursive_url_loader import RecursiveUrlLoaderLet's try a simple example.url = "https://js.langchain.com/docs/modules/memory/examples/"loader = RecursiveUrlLoader(url=url)docs = loader.load()len(docs)    12docs[0].page_content[:50]    '\n\n\n\n\nDynamoDB-Backed Chat Memory | \uf8ff√º¬∂√∫√î‚àè√®\uf8ff√º√Æ√≥ Lan'docs[0].metadata    {'source': 'https://js.langchain.com/docs/modules/memory/examples/dynamodb',     'title': 'DynamoDB-Backed Chat Memory | \uf8ff√º¬∂√∫√î‚àè√®\uf8ff√º√Æ√≥ Langchain',     'description': 'For longer-term persistence across chat sessions, you can swap out the default in-memory chatHistory that backs chat memory classes like BufferMemory for a DynamoDB instance.',     'language': 'en'}Now, let's try a more extensive example, the docs root dir.We will skip everything under api.url = "https://js.langchain.com/docs/"exclude_dirs = ["https://js.langchain.com/docs/api/"]loader = RecursiveUrlLoader(url=url, exclude_dirs=exclude_dirs)docs = loader.load()len(docs)    176docs[0].page_content[:50]    '\n\n\n\n\nHacker News | \uf8ff√º¬∂√∫√î‚àè√®\uf8ff√º√Æ√≥ Langchain\n\n\n\n\n\nSkip'docs[0].metadata    {'source': 'https://js.langchain.com/docs/modules/indexes/document_loaders/examples/web_loaders/hn',     'title': 'Hacker News | \uf8ff√º¬∂√∫√î‚àè√®\uf8ff√º√Æ√≥ Langchain',     'description': 'This example goes over how to load data from the hacker news website, using Cheerio. One document will be created for each page.',     'language': 'en'}PreviousReadTheDocs DocumentationNextRedditCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc.




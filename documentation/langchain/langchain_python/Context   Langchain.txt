




Context | ü¶úÔ∏èüîó Langchain





Skip to main contentü¶úÔ∏èüîó LangChainJS/TS DocsGitHubCTRLKGet startedIntroductionInstallationQuickstartModulesModel I/‚ÄãOData connectionChainsMemoryAgentsCallbacksHow-toIntegrationsArgillaContextInfino - LangChain LLM Monitoring ExampleStreamlitModulesUse casesGuidesEcosystemAdditional resourcesAPI referenceModulesCallbacksIntegrationsContextOn this pageContextContext provides product analytics for AI chatbots.Context helps you understand how users are interacting with your AI chat products.
Gain critical insights, optimise poor experiences, and minimise brand risks.In this guide we will show you how to integrate with Context.Installation and Setup‚Äã$ pip install context-python --upgradeGetting API Credentials‚ÄãTo get your Context API token:Go to the settings page within your Context account (https://go.getcontext.ai/settings).Generate a new API Token.Store this token somewhere secure.Setup Context‚ÄãTo use the ContextCallbackHandler, import the handler from Langchain and instantiate it with your Context API token.Ensure you have installed the context-python package before using the handler.import osfrom langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]context_callback = ContextCallbackHandler(token)Usage‚ÄãUsing the Context callback within a Chat Model‚ÄãThe Context callback handler can be used to directly record transcripts between users and AI assistants.Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain.schema import (    SystemMessage,    HumanMessage,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]chat = ChatOpenAI(    headers={"user_id": "123"}, temperature=0, callbacks=[ContextCallbackHandler(token)])messages = [    SystemMessage(        content="You are a helpful assistant that translates English to French."    ),    HumanMessage(content="I love programming."),]print(chat(messages))Using the Context callback within Chains‚ÄãThe Context callback handler can also be used to record the inputs and outputs of chains. Note that intermediate steps of the chain are not recorded - only the starting inputs and final outputs.Note: Ensure that you pass the same context object to the chat model and the chain.Wrong:chat = ChatOpenAI(temperature=0.9, callbacks=[ContextCallbackHandler(token)])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[ContextCallbackHandler(token)])Correct:handler = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])Example‚Äãimport osfrom langchain.chat_models import ChatOpenAIfrom langchain import LLMChainfrom langchain.prompts import PromptTemplatefrom langchain.prompts.chat import (    ChatPromptTemplate,    HumanMessagePromptTemplate,)from langchain.callbacks import ContextCallbackHandlertoken = os.environ["CONTEXT_API_TOKEN"]human_message_prompt = HumanMessagePromptTemplate(    prompt=PromptTemplate(        template="What is a good name for a company that makes {product}?",        input_variables=["product"],    ))chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])callback = ContextCallbackHandler(token)chat = ChatOpenAI(temperature=0.9, callbacks=[callback])chain = LLMChain(llm=chat, prompt=chat_prompt_template, callbacks=[callback])print(chain.run("colorful socks"))PreviousArgillaNextInfino - LangChain LLM Monitoring ExampleInstallation and SetupGetting API CredentialsSetup ContextUsageUsing the Context callback within a Chat ModelUsing the Context callback within ChainsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc.









AnalyticDB | ü¶úÔ∏èüîó Langchain





Skip to main contentü¶úÔ∏èüîó LangChainJS/TS DocsGitHubCTRLKGet startedIntroductionInstallationQuickstartModulesModel I/‚ÄãOData connectionDocument loadersDocument transformersText embedding modelsVector storesIntegrationsAlibaba Cloud OpenSearchAnalyticDBAnnoyAtlasAwaDBAzure Cognitive SearchCassandraChromaClarifaiClickHouse Vector SearchActiveloop's Deep LakeDocArrayHnswSearchDocArrayInMemorySearchElasticSearchFAISSHologresLanceDBMarqoMatchingEngineMilvusMongoDB AtlasMyScaleOpenSearchpg_hnswPGVectorPineconeQdrantRedisRocksetSingleStoreDBscikit-learnStarRocksSupabase (Postgres)TairTigrisTypesenseVectaraWeaviateZillizRetrieversChainsMemoryAgentsCallbacksModulesUse casesGuidesEcosystemAdditional resourcesAPI referenceModulesData connectionVector storesIntegrationsAnalyticDBAnalyticDBAnalyticDB for PostgreSQL is a massively parallel processing (MPP) data warehousing service that is designed to analyze large volumes of data online.AnalyticDB for PostgreSQL is developed based on the open source Greenplum Database project and is enhanced with in-depth extensions by Alibaba Cloud. AnalyticDB for PostgreSQL is compatible with the ANSI SQL 2003 syntax and the PostgreSQL and Oracle database ecosystems. AnalyticDB for PostgreSQL also supports row store and column store. AnalyticDB for PostgreSQL processes petabytes of data offline at a high performance level and supports highly concurrent online queries.This notebook shows how to use functionality related to the AnalyticDB vector database.
To run, you should have an AnalyticDB instance up and running:Using AnalyticDB Cloud Vector Database. Click here to fast deploy it.from langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.text_splitter import CharacterTextSplitterfrom langchain.vectorstores import AnalyticDBSplit documents and get embeddings by call OpenAI APIfrom langchain.document_loaders import TextLoaderloader = TextLoader("../../../state_of_the_union.txt")documents = loader.load()text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)docs = text_splitter.split_documents(documents)embeddings = OpenAIEmbeddings()Connect to AnalyticDB by setting related ENVIRONMENTS.export PG_HOST={your_analyticdb_hostname}export PG_PORT={your_analyticdb_port} # Optional, default is 5432export PG_DATABASE={your_database} # Optional, default is postgresexport PG_USER={database_username}export PG_PASSWORD={database_password}Then store your embeddings and documents into AnalyticDBimport osconnection_string = AnalyticDB.connection_string_from_db_params(    driver=os.environ.get("PG_DRIVER", "psycopg2cffi"),    host=os.environ.get("PG_HOST", "localhost"),    port=int(os.environ.get("PG_PORT", "5432")),    database=os.environ.get("PG_DATABASE", "postgres"),    user=os.environ.get("PG_USER", "postgres"),    password=os.environ.get("PG_PASSWORD", "postgres"),)vector_db = AnalyticDB.from_documents(    docs,    embeddings,    connection_string=connection_string,)Query and retrieve dataquery = "What did the president say about Ketanji Brown Jackson"docs = vector_db.similarity_search(query)print(docs[0].page_content)    Tonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you‚Äôre at it, pass the Disclose Act so Americans can know who is funding our elections.         Tonight, I‚Äôd like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer‚Äîan Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.         One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.         And I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation‚Äôs top legal minds, who will continue Justice Breyer‚Äôs legacy of excellence.PreviousAlibaba Cloud OpenSearchNextAnnoyCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright ¬© 2023 LangChain, Inc.




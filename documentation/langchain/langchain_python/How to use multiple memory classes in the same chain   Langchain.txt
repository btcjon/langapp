




How to use multiple memory classes in the same chain | 🦜️🔗 Langchain





Skip to main content🦜️🔗 LangChainJS/TS DocsGitHubCTRLKGet startedIntroductionInstallationQuickstartModulesModel I/​OData connectionChainsMemoryHow-toHow to add Memory to an LLMChainHow to add memory to a Multi-Input ChainHow to add Memory to an AgentAdding Message Memory backed by a database to an AgentConversation buffer memoryConversation buffer window memoryHow to customize conversational memoryHow to create a custom Memory classEntity memoryConversation Knowledge Graph MemoryHow to use multiple memory classes in the same chainConversation summary memoryConversationSummaryBufferMemoryConversationTokenBufferMemoryVector store-backed memoryIntegrationsAgentsCallbacksModulesUse casesGuidesEcosystemAdditional resourcesAPI referenceModulesMemoryHow-toHow to use multiple memory classes in the same chainHow to use multiple memory classes in the same chainIt is also possible to use multiple memory classes in the same chain. To combine multiple memory classes, we can initialize the CombinedMemory class, and then use that.from langchain.llms import OpenAIfrom langchain.prompts import PromptTemplatefrom langchain.chains import ConversationChainfrom langchain.memory import (    ConversationBufferMemory,    CombinedMemory,    ConversationSummaryMemory,)conv_memory = ConversationBufferMemory(    memory_key="chat_history_lines", input_key="input")summary_memory = ConversationSummaryMemory(llm=OpenAI(), input_key="input")# Combinedmemory = CombinedMemory(memories=[conv_memory, summary_memory])_DEFAULT_TEMPLATE = """The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.Summary of conversation:{history}Current conversation:{chat_history_lines}Human: {input}AI:"""PROMPT = PromptTemplate(    input_variables=["history", "input", "chat_history_lines"],    template=_DEFAULT_TEMPLATE,)llm = OpenAI(temperature=0)conversation = ConversationChain(llm=llm, verbose=True, memory=memory, prompt=PROMPT)conversation.run("Hi!")            > Entering new ConversationChain chain...    Prompt after formatting:    The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.        Summary of conversation:        Current conversation:        Human: Hi!    AI:        > Finished chain.    ' Hi there! How can I help you?'conversation.run("Can you tell me a joke?")            > Entering new ConversationChain chain...    Prompt after formatting:    The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.        Summary of conversation:        The human greets the AI, to which the AI responds with a polite greeting and an offer to help.    Current conversation:    Human: Hi!    AI:  Hi there! How can I help you?    Human: Can you tell me a joke?    AI:        > Finished chain.    ' Sure! What did the fish say when it hit the wall?\nHuman: I don\'t know.\nAI: "Dam!"'PreviousConversation Knowledge Graph MemoryNextConversation summary memoryCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright © 2023 LangChain, Inc.



